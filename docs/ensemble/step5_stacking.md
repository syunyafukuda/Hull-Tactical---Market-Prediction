# Step 5: Stackingï¼ˆãƒ¡ã‚¿å­¦ç¿’ï¼‰

æœ€çµ‚æ›´æ–°: 2025-12-13

## æ¦‚è¦

LGBMã€XGBoostã€CatBoostã®OOFäºˆæ¸¬ã‚’å…¥åŠ›ã¨ã—ã¦ã€ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆRidgeï¼‰ã§æœ€é©ãªçµ„ã¿åˆã‚ã›ã‚’å­¦ç¿’ã€‚
Step 3 ãŒæœ‰åŠ¹ã ã£ãŸå ´åˆã®ã¿å®Ÿè¡Œã€‚

## å®Ÿè£…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹

**Status**: âŒ ä¸æ¡ç”¨ï¼ˆéå­¦ç¿’ç¢ºèªï¼‰

## OOFè©•ä¾¡çµæœï¼ˆ2025-12-13å®Ÿæ–½ï¼‰

| æŒ‡æ¨™ | å€¤ |
|------|-----|
| OOF RMSE | 0.010998 |
| vs LGBM | -9.59% |
| äºˆæ¸¬Std | âš ï¸ **0.000151** |

### ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ä¿‚æ•°

```
Intercept: 0.000069
lgbm:      0.010143
xgboost:   0.007620
catboost:  0.001520
```

**â†’ äºˆæ¸¬Std = 0.000151 ã¯éå­¦ç¿’ã®æ˜ç¢ºãªå…†å€™ã€‚ä¸æ¡ç”¨ã€‚**

## ä¸æ¡ç”¨ç†ç”±

1. **äºˆæ¸¬StdãŒæ¥µç«¯ã«å°ã•ã„**: 0.000151ï¼ˆLGBMæ¯” 2.9%ï¼‰
2. **äºˆæ¸¬ãŒã»ã¼å®šæ•°**: ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ãŒå¹³å‡åŒ–ã—ã™ã
3. **éå­¦ç¿’ãƒªã‚¹ã‚¯å¤§**: TimeSeriesSplitã§ã‚‚æ”¹å–„ã›ãš

---

## èƒŒæ™¯ãƒ»æ ¹æ‹ ï¼ˆå‚è€ƒï¼‰

### Stackingã®ãƒ¡ãƒªãƒƒãƒˆ

1. **è‡ªå‹•é‡ã¿å­¦ç¿’**: æ‰‹å‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦
2. **éç·šå½¢çµ„ã¿åˆã‚ã›**: å˜ç´”å¹³å‡ã‚ˆã‚ŠæŸ”è»Ÿ
3. **CVãƒ™ãƒ¼ã‚¹ã§éå­¦ç¿’æŠ‘åˆ¶**: OOFã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ãƒªãƒ¼ã‚¯ã‚’é˜²æ­¢

### æ‰‹å‹•ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¨ã®æ¯”è¼ƒ

| è¦³ç‚¹ | æ‰‹å‹•ï¼ˆStep 1-4ï¼‰ | Stacking |
|------|-----------------|----------|
| é‡ã¿æ±ºå®š | çµŒé¨“å‰‡ãƒ»ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ | ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ |
| æŸ”è»Ÿæ€§ | ç·šå½¢ã®ã¿ | ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«æ¬¡ç¬¬ |
| éå­¦ç¿’ãƒªã‚¹ã‚¯ | ä½ã„ | ä¸­ç¨‹åº¦ |
| è§£é‡ˆæ€§ | é«˜ã„ | ä¸­ç¨‹åº¦ |

---

## å…¥åŠ›

### ä½¿ç”¨ã™ã‚‹artifacts

| ãƒ¢ãƒ‡ãƒ« | ãƒ•ã‚¡ã‚¤ãƒ« |
|--------|----------|
| LGBM | `artifacts/models/lgbm/oof_predictions.csv` |
| XGBoost | `artifacts/models/xgboost/oof_predictions.csv` |
| CatBoost | `artifacts/models/catboost/oof_predictions.csv` |

---

## å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
Level 0 (Base Models)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LightGBMâ”‚ XGBoost  â”‚ CatBoost â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚         â”‚          â”‚
     â–¼         â–¼          â–¼
   OOFäºˆæ¸¬   OOFäºˆæ¸¬    OOFäºˆæ¸¬
     â”‚         â”‚          â”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚         â”‚
          â–¼         â–¼
Level 1 (Meta Model)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Ridge Regression       â”‚
â”‚   (alpha=1.0, normalize)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         æœ€çµ‚äºˆæ¸¬
```

### ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«å­¦ç¿’

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import Ridge
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error

# 1. OOFäºˆæ¸¬ã‚’èª­ã¿è¾¼ã¿
lgbm_oof = pd.read_csv("artifacts/models/lgbm/oof_predictions.csv")
xgb_oof = pd.read_csv("artifacts/models/xgboost/oof_predictions.csv")
cat_oof = pd.read_csv("artifacts/models/catboost/oof_predictions.csv")

# 2. ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ç”¨ç‰¹å¾´é‡ã‚’ä½œæˆ
X_stack = pd.DataFrame({
    "lgbm": lgbm_oof["prediction"],
    "xgboost": xgb_oof["prediction"],
    "catboost": cat_oof["prediction"]
})
y = lgbm_oof["actual"]

# 3. ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆæ™‚ç³»åˆ—CVï¼‰
tscv = TimeSeriesSplit(n_splits=5)
meta_oof_pred = np.zeros(len(y))

for train_idx, val_idx in tscv.split(X_stack):
    X_train, X_val = X_stack.iloc[train_idx], X_stack.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
    
    meta_model = Ridge(alpha=1.0)
    meta_model.fit(X_train, y_train)
    
    meta_oof_pred[val_idx] = meta_model.predict(X_val)

# 4. æœ€çµ‚ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
final_meta_model = Ridge(alpha=1.0)
final_meta_model.fit(X_stack, y)

# 5. RMSEè¨ˆç®—
oof_rmse = np.sqrt(mean_squared_error(y, meta_oof_pred))
print(f"Step 5 OOF RMSE: {oof_rmse:.6f}")

# 6. å­¦ç¿’ã•ã‚ŒãŸé‡ã¿ç¢ºèª
print(f"Meta weights: {dict(zip(X_stack.columns, final_meta_model.coef_))}")
```

### ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«å€™è£œ

| ãƒ¢ãƒ‡ãƒ« | ç‰¹å¾´ | æ¨å¥¨ |
|--------|------|------|
| Ridge | æ­£å‰‡åŒ–ã‚ã‚Šã€ä¿‚æ•°ãŒå®‰å®š | âœ… |
| LinearRegression | æ­£å‰‡åŒ–ãªã—ã€éå­¦ç¿’ãƒªã‚¹ã‚¯ | âš ï¸ |
| ElasticNet | L1+L2æ­£å‰‡åŒ–ã€ã‚¹ãƒ‘ãƒ¼ã‚¹è§£ | ğŸ”¬ |
| XGBoost (shallow) | éç·šå½¢ã€éå­¦ç¿’ãƒªã‚¹ã‚¯é«˜ | âŒ |

---

## å‡ºåŠ›

### æˆæœç‰©

| ãƒ•ã‚¡ã‚¤ãƒ« | å†…å®¹ |
|----------|------|
| `artifacts/ensemble/step5_stacking/oof_predictions.csv` | ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®OOFäºˆæ¸¬ |
| `artifacts/ensemble/step5_stacking/submission.csv` | Kaggleæå‡ºç”¨ |
| `artifacts/ensemble/step5_stacking/metrics.json` | è©•ä¾¡æŒ‡æ¨™ |
| `artifacts/ensemble/step5_stacking/meta_model.pkl` | å­¦ç¿’æ¸ˆã¿ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ« |
| `artifacts/ensemble/step5_stacking/meta_weights.json` | å­¦ç¿’ã•ã‚ŒãŸé‡ã¿ |

### metrics.jsonå½¢å¼

```json
{
  "method": "stacking",
  "meta_model": "Ridge",
  "meta_alpha": 1.0,
  "base_models": ["lgbm", "xgboost", "catboost"],
  "oof_rmse": 0.01175,
  "oof_rmse_vs_lgbm": -0.035,
  "oof_rmse_vs_step3": -0.010,
  "meta_weights": {
    "lgbm": 0.55,
    "xgboost": 0.38,
    "catboost": 0.07
  }
}
```

### meta_weights.jsonå½¢å¼

```json
{
  "intercept": 0.0012,
  "coefficients": {
    "lgbm": 0.55,
    "xgboost": 0.38,
    "catboost": 0.07
  },
  "interpretation": "LGBMãŒæœ€é‡è¦ã€CatBoostã¯å¾®é‡è²¢çŒ®"
}
```

---

## æˆåŠŸåŸºæº–

### OOFåŸºæº–

| æŒ‡æ¨™ | åŸºæº– | æ ¹æ‹  |
|------|------|------|
| OOF RMSE | < Step 3/4 ã®ãƒ™ã‚¹ãƒˆ | ãƒ¡ã‚¿å­¦ç¿’ã§æ”¹å–„ |
| meta_weight åˆè¨ˆ | â‰ˆ 1.0 | æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ |

### LBåŸºæº–ï¼ˆOOFæ”¹å–„æ™‚ã®ã¿æ¤œè¨¼ï¼‰

| æŒ‡æ¨™ | åŸºæº– | æ ¹æ‹  |
|------|------|------|
| LB Score | > Step 3/4 ã®ãƒ™ã‚¹ãƒˆ | StackingãŒæœ‰åŠ¹ |

### éå­¦ç¿’ãƒã‚§ãƒƒã‚¯

| æŒ‡æ¨™ | è­¦å‘ŠåŸºæº– |
|------|----------|
| Train RMSE vs OOF RMSE | å·®ãŒ 10% ä»¥ä¸Š |
| CV foldé–“ã®RMSEåˆ†æ•£ | åˆ†æ•£ãŒå¤§ãã™ãã‚‹ |

---

## å®Ÿè¡Œæ‰‹é †

### ãƒ­ãƒ¼ã‚«ãƒ«è©•ä¾¡

```bash
python -m src.ensemble.stacking \
    --config configs/ensemble/step5_stacking.yaml \
    --out-dir artifacts/ensemble/step5_stacking
```

### ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

```bash
python -m src.ensemble.stacking_tune \
    --alpha-range 0.01 10 \
    --out-dir artifacts/ensemble/step5_stacking
```

---

## Kaggle NBå®Ÿè£…

```python
import pickle
import numpy as np
import pandas as pd

# ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã¨å„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
with open("meta_model.pkl", "rb") as f:
    meta_model = pickle.load(f)

def predict(test: pd.DataFrame) -> float:
    features = prepare_features(test)
    
    # Level 0: å„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
    lgbm_pred = lgbm_model.predict(features)[0]
    xgb_pred = xgb_model.predict(features)[0]
    cat_pred = catboost_model.predict(features)[0]
    
    # Level 1: ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã§çµ±åˆ
    stack_features = np.array([[lgbm_pred, xgb_pred, cat_pred]])
    ensemble_pred = meta_model.predict(stack_features)[0]
    
    # ã‚·ã‚°ãƒŠãƒ«å¤‰æ›
    signal = np.clip(ensemble_pred * 1.0 + 1.0, 0.9, 1.1)
    return float(signal)
```

### å¿…è¦ãªartifacts

| ãƒ•ã‚¡ã‚¤ãƒ« | å†…å®¹ |
|----------|------|
| `lgbm_model.pkl` | LightGBMãƒ¢ãƒ‡ãƒ« |
| `xgb_model.pkl` | XGBoostãƒ¢ãƒ‡ãƒ« |
| `catboost_model.pkl` | CatBoostãƒ¢ãƒ‡ãƒ« |
| `meta_model.pkl` | Ridge ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ« |

---

## ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

### ãƒªã‚¹ã‚¯1: ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®éå­¦ç¿’

**ç—‡çŠ¶**: Train RMSEã¯è‰¯ã„ãŒOOF RMSEãŒæ‚ªã„
**å¯¾ç­–**: 
- Ridge ã® alpha ã‚’å¤§ããã™ã‚‹
- TimeSeriesSplit ã‚’ä½¿ç”¨ï¼ˆãƒªãƒ¼ã‚¯ã‚’é˜²æ­¢ï¼‰
- CVæ•°ã‚’å¢—ã‚„ã™

### ãƒªã‚¹ã‚¯2: è² ã®ä¿‚æ•°

**ç—‡çŠ¶**: ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ãŒè² ã®ä¿‚æ•°ã‚’å­¦ç¿’
**å¯¾ç­–**:
- `positive=True` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆsklearn 0.24+ï¼‰
- ä¿‚æ•°ãŒè² ã®å ´åˆã¯æ‰‹å‹•ã§ã‚¯ãƒªãƒƒãƒ—

### ãƒªã‚¹ã‚¯3: CatBoostã¸ã®éåº¦ãªä¾å­˜

**ç—‡çŠ¶**: CatBoostã®ä¿‚æ•°ãŒç•°å¸¸ã«å¤§ãã„
**å¯¾ç­–**:
- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆStandardScalerï¼‰ã‚’é©ç”¨
- CatBoostã‚’é™¤å¤–ã—ã¦å†å­¦ç¿’

```python
# æ­£ã®ä¿‚æ•°ã®ã¿ã‚’å¼·åˆ¶ï¼ˆéå­¦ç¿’å¯¾ç­–ï¼‰
from sklearn.linear_model import Ridge

class PositiveRidge(Ridge):
    def fit(self, X, y):
        super().fit(X, y)
        self.coef_ = np.maximum(self.coef_, 0)  # è² ã®ä¿‚æ•°ã‚’ã‚¼ãƒ­ã«ã‚¯ãƒªãƒƒãƒ—
        return self
```

---

## Step 3/4 ã¨ã®æ¯”è¼ƒ

| è¦³ç‚¹ | Step 3ï¼ˆæ‰‹å‹•é‡ã¿ï¼‰ | Step 4ï¼ˆRank Avgï¼‰ | Step 5ï¼ˆStackingï¼‰ |
|------|-------------------|-------------------|-------------------|
| é‡ã¿æ±ºå®š | æ‰‹å‹• | ç­‰é‡ã¿ | ãƒ‡ãƒ¼ã‚¿é§†å‹• |
| æŸ”è»Ÿæ€§ | ä½ã„ | ä¸­ç¨‹åº¦ | é«˜ã„ |
| éå­¦ç¿’ãƒªã‚¹ã‚¯ | æœ€ä½ | ä½ã„ | ä¸­ç¨‹åº¦ |
| å®Ÿè£…è¤‡é›‘åº¦ | ä½ã„ | ä¸­ç¨‹åº¦ | é«˜ã„ |
| è§£é‡ˆæ€§ | é«˜ã„ | é«˜ã„ | ä¸­ç¨‹åº¦ |

---

## ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é¸æŠã®æœ€çµ‚åˆ¤æ–­

Step 1ã€œ5 ã®çµæœã‚’ã¾ã¨ã‚ã¦ã€æœ€çµ‚çš„ã«æ¡ç”¨ã™ã‚‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã‚’æ±ºå®š:

```
Step 1: LGBM + XGB 50:50
â”œâ”€ LBæ”¹å–„ â†’ Step 2, 3 ã‚’æ¤œè¨¼
â””â”€ LBæ‚ªåŒ– â†’ LGBMã‚½ãƒ­ç¢ºå®š

Step 2: Rank Average
â”œâ”€ Step 1 ã‚ˆã‚Š LBæ”¹å–„ â†’ Step 2 æ¡ç”¨å€™è£œ
â””â”€ Step 1 ã‚ˆã‚Š LBæ‚ªåŒ– â†’ Step 1 å„ªå…ˆ

Step 3: +CatBoost 60:30:10
â”œâ”€ LBæ”¹å–„ â†’ Step 4, 5 ã‚’æ¤œè¨¼
â””â”€ LBæ‚ªåŒ– â†’ CatBoostä¸æ¡ç”¨ã€Step 1/2 ã®ãƒ™ã‚¹ãƒˆæ¡ç”¨

Step 4: 3-Model Rank Average
â”œâ”€ Step 3 ã‚ˆã‚Š LBæ”¹å–„ â†’ Step 4 æ¡ç”¨å€™è£œ
â””â”€ Step 3 ã‚ˆã‚Š LBæ‚ªåŒ– â†’ Step 3 å„ªå…ˆ

Step 5: Stacking
â”œâ”€ å…¨Stepã‚ˆã‚Š LBæ”¹å–„ â†’ Step 5 æ¡ç”¨
â””â”€ ä»–Stepã‚ˆã‚Š LBæ‚ªåŒ– â†’ ä»–ã®ãƒ™ã‚¹ãƒˆæ¡ç”¨
```

---

## å‚è€ƒãƒªãƒ³ã‚¯

- [ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¦‚è¦](README.md)
- [Step 3: 3-Model é‡ã¿ä»˜ãå¹³å‡](step3_lgbm_xgb_cat.md)
- [Step 4: 3-Model Rank Average](step4_3model_rank.md)
- [sklearn Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)
