# 外部レジーム特徴 SU10 仕様（External Regime Dataset）

最終更新: 2025-12-06

## ❌ 非採用決定 (2025-12-06)

| 指標 | SU5 (ベースライン) | SU10 | 変化 |
|------|---------------------|------|------|
| **LB score** | 0.681 | 0.597 | **-12.3%** ❌ |
| OOF RMSE | 0.01214 | 0.01227 | +1.1% |

### 非採用理由

1. **LB 大幅悪化**: -12.3% (0.681 → 0.597)
2. **OOF と LB の乖離**: OOF +1.1% 悪化に対し LB -12.3% 悪化 → 過学習の兆候
3. **外部データの問題**:
   - Look-ahead bias の可能性
   - Kaggle 隠しテスト期間と外部データの時間的ズレ
   - date_id 8990 以降は外部データなし（NaN）

### 結論

SU5 (LB 0.681) を引き続きベストラインとして維持。SU10 はマージしない。

---

## 実装ステータス

### ✅ 完了
- ✅ 目的・位置づけの定義
- ✅ 外部データソースの選定（S&P 500 / SPY）
- ✅ date_id マッピング仕様
- ✅ 特徴量定義（ボラティリティ・トレンドレジーム）
- ✅ パイプライン設計
- ✅ `src/feature_generation/su10/feature_su10.py`: 特徴量生成クラス
- ✅ `src/feature_generation/su10/train_su10.py`: 学習パイプライン
- ✅ `src/feature_generation/su10/predict_su10.py`: 推論パイプライン
- ✅ `tests/feature_generation/test_su10.py`: 単体テスト（14件パス）
- ✅ OOF評価: RMSE 0.01227
- ✅ LB検証: **0.597（非採用）**

---

## 1. SU10 の目的と位置づけ

### 1.1 目的

Hull Tactical Market Prediction コンペにおいて、**市場全体レジーム（トレンド・ボラティリティなど）を表す外部特徴量**を導入する。

外部レジーム特徴は、元の train/test 生データとは**独立の軸**であり、
SU1/SU5 に代表される「欠損構造」系特徴とは異なる情報を付与する。

### 1.2 SU シリーズの中での SU10

| SU | 軸 | 説明 | 状態 |
|----|-----|------|------|
| SU1 | 欠損構造 | 単列レベルの欠損フラグ・run | **採用** (LB 0.674) |
| SU2 | 欠損構造 | 二次欠損特徴（rolling/EWMA） | 非採用（過学習） |
| SU3 | 欠損構造 | 遷移・再出現パターン | 非採用（コンセプト失敗） |
| SU4 | 補完トレース | 代入影響トレース | 削除決定（寄与ゼロ） |
| SU5 | 欠損構造 | 共欠損（co-miss）構造 | **採用** (LB 0.681) ← ベスト |
| SU6 | 欠損軸圧縮 | PCA圧縮候補 | 保留 |
| SU7 | モメンタム | diff/lag/rolling/RSI | 非採用（レジームミスマッチ） |
| SU8 | ボラティリティ | 局所ボラ・レジームタグ | 非採用（効果なし） |
| SU9 | カレンダー | 曜日・月・祝日 | 非採用（過学習） |
| **SU10** | **外部レジーム** | **S&P/VIX 等の市場レジーム** | **非採用** (LB 0.597, -12.3%) |

### 1.3 パイプライン内での位置

```
train.csv / test.csv を読み込み
    ↓
★ SU10 External Regime Dataset を date_id で left join ★
    ↓
SU1〜SU9 の特徴量生成（必要に応じて ON/OFF）
    ↓
GroupImputers（M/E/I/P/S 欠損補完）
    ↓
前処理（StandardScaler + OneHot）
    ↓
LightGBM 学習・推論
```

**SU10 は「date_id 単位で事前計算されたレジーム特徴テーブル」として扱い、
ローカル・Kaggle の両方で同一の CSV を join する。**

---

## 2. 入出力・ファイル構成

### 2.1 入力（外部ソース）

#### 利用可能な外部データ

**データソース**: [S and P historical data for Hull Tactical competition](https://www.kaggle.com/datasets/ambrosm/s-and-p-historical-data-for-hull-tactical-competition/)

| ソース | ファイル | 説明 | date_id |
|--------|----------|------|---------|
| SPY ETF | `data/histolical/spy-historical.csv` | S&P 500 ETF 日次 OHLCV | あり (780〜8989) |
| S&P 500 | `data/histolical/sp-historical.csv` | S&P 500 指数日次 OHLCV | なし（Date のみ） |

#### SPY Historical Data スキーマ

```csv
date_id,Date,Open,High,Low,Close,Adj Close,Volume,Dividend,forward_returns
780,1993-02-01,43.97,44.25,43.97,44.25,24.49,480500.0,0.0,0.0020338983050847137
...
8989,2025-09-11,654.18,658.33,653.59,657.63,655.81,69934400.0,0.0,
```

- **date_id**: コンペ側のトレーディングデーID（主キー）
- **Date**: 実カレンダー日付
- **Close / Adj Close**: 終値（配当調整後）
- **forward_returns**: 翌日リターン

#### コンペデータとの整合性

| データ | date_id 範囲 | 行数 |
|--------|-------------|------|
| train.csv | 0〜8989 | 8,990 |
| test.csv | 8980〜8989 | 10 |
| spy-historical.csv | 780〜8989 | 8,210 |

**注意**: SPY は date_id=780 (1993-02-01) 以降のみ利用可能。
date_id 0〜779 は SPY データなし（NaN または fallback 処理が必要）。

### 2.2 出力（SU10 External Regime Dataset）

#### ファイル名

```
data/processed/su10_external_regime.csv
```

または Kaggle Dataset として:

```
<user>/su10-external-regime/su10_external_regime.csv
```

#### スキーマ（列イメージ）

| 列名 | 型 | 説明 |
|------|-----|------|
| `date_id` | int64 | コンペ側のトレーディングデーID（主キー） |
| `su10_spx_ret_5d` | float32 | S&P 5日リターン |
| `su10_spx_ret_20d` | float32 | S&P 20日リターン |
| `su10_spx_ewmstd_20d` | float32 | S&P 20日 EWMA ボラ |
| `su10_spx_ewmstd_60d` | float32 | S&P 60日 EWMA ボラ |
| `su10_spx_vol_ratio` | float32 | 短期/長期ボラ比 |
| `su10_spx_vol_level` | float32 | 標準化されたボラ水準指標 |
| `su10_spx_vol_regime_low` | uint8 | ボラレジーム low（one-hot） |
| `su10_spx_vol_regime_mid` | uint8 | ボラレジーム mid（one-hot） |
| `su10_spx_vol_regime_high` | uint8 | ボラレジーム high（one-hot） |
| `su10_spx_trend_indicator` | float32 | トレンド指標（MA短期-長期） |
| `su10_spx_trend_regime_down` | uint8 | トレンドレジーム down（one-hot） |
| `su10_spx_trend_regime_flat` | uint8 | トレンドレジーム flat（one-hot） |
| `su10_spx_trend_regime_up` | uint8 | トレンドレジーム up（one-hot） |
| `su10_spx_ret_vol_adj_5d` | float32 | ボラ調整済み 5日リターン |

**想定列数**: 15〜20 列程度（S&P のみの場合）

---

## 3. 特徴量定義

### 3.1 ベース系列

```python
# SPY の終値と日次リターン
close = spy_df["Adj Close"]
ret = close.pct_change()  # 日次リターン
```

### 3.2 ボラティリティ指標

```python
# EWMA 標準偏差（halflife ベース）
ewmstd_short = ret.ewm(halflife=20, adjust=False).std()  # 短期ボラ
ewmstd_long = ret.ewm(halflife=60, adjust=False).std()   # 長期ボラ

# ボラ比率
vol_ratio = ewmstd_short / (ewmstd_long + 1e-8)

# ボラ水準（標準化）
vol_level = (ewmstd_short - ewmstd_short.mean()) / ewmstd_short.std()
```

### 3.3 ボラティリティレジーム（3区分）

```python
# train 期間の vol_level から分位点を算出
q_low = vol_level_train.quantile(0.33)
q_high = vol_level_train.quantile(0.66)

# レジーム分類（one-hot 化）
vol_regime_low = (vol_level <= q_low).astype(np.uint8)
vol_regime_mid = ((vol_level > q_low) & (vol_level <= q_high)).astype(np.uint8)
vol_regime_high = (vol_level > q_high).astype(np.uint8)
```

**リーク防止**: 分位点 `q_low`, `q_high` は **train 期間のみ** で算出し、test には持ち越す。

### 3.4 トレンド指標

```python
# EWMA 移動平均
ma_short = close.ewm(halflife=20, adjust=False).mean()
ma_long = close.ewm(halflife=60, adjust=False).mean()

# トレンド指標
trend_indicator = ma_short - ma_long
```

### 3.5 トレンドレジーム（3区分）

```python
# train 期間の trend_indicator から分位点を算出
tau_down = trend_indicator_train.quantile(0.33)
tau_up = trend_indicator_train.quantile(0.66)

# レジーム分類（one-hot 化）
trend_regime_down = (trend_indicator <= tau_down).astype(np.uint8)
trend_regime_flat = ((trend_indicator > tau_down) & (trend_indicator <= tau_up)).astype(np.uint8)
trend_regime_up = (trend_indicator > tau_up).astype(np.uint8)
```

### 3.6 期間リターン

```python
# 5日・20日リターン
ret_5d = close.pct_change(periods=5)
ret_20d = close.pct_change(periods=20)
```

### 3.7 ボラ調整リターン

```python
# ボラ調整済みリターン
eps = 1e-4
denom = 1 + np.maximum(ewmstd_short, eps)
ret_vol_adj_5d = ret_5d / denom

# 極端値のクリップ（p1, p99）
ret_vol_adj_5d = np.clip(
    ret_vol_adj_5d,
    ret_vol_adj_5d.quantile(0.01),
    ret_vol_adj_5d.quantile(0.99)
)
```

### 3.8 列数サマリ

| カテゴリ | 特徴量 | 列数 |
|----------|--------|------|
| 期間リターン | ret_5d, ret_20d | 2 |
| ボラ指標 | ewmstd_20d, ewmstd_60d, vol_ratio, vol_level | 4 |
| ボラレジーム | low, mid, high | 3 |
| トレンド指標 | trend_indicator | 1 |
| トレンドレジーム | down, flat, up | 3 |
| ボラ調整リターン | ret_vol_adj_5d | 1 |
| **合計** | | **14列** |

---

## 4. 運用方式（方式B: 事前結合済みCSV）

### 4.1 コンペ構造の理解

本コンペの `test.csv` について：

- **公開 test.csv**: 10行の**構造サンプル（mock）** であり、スコアリングには使われない
- **非公開テストセット**: 180行で、API経由で Kaggle 側が内部で評価に使用
- 公開 test.csv は固定であり、コンペ期間中に変更される前提はない

この構造を踏まえ、**方式B（事前結合済みCSV）** を採用する。

### 4.2 方式Bの概要

```
【ローカル側】
1. train.csv + spy-historical.csv → train_with_su10.csv を作成
2. test.csv + spy-historical.csv → test_with_su10.csv を作成（10行・構造確認用）
3. train_with_su10.csv で学習 → inference_bundle.pkl 生成

【Kaggle Dataset にアップロード】
- inference_bundle.pkl
- model_meta.json
- feature_list.json
- su10_external_regime.csv（date_id → SU10特徴のマッピングテーブル）

【Kaggle NB 推論時（APIモード）】
1. API から渡される test DataFrame を受け取る（非公開180行）
2. su10_external_regime.csv と date_id で join
3. inference_bundle.pkl で推論
4. 予測値を返す
```

### 4.3 ファイル構成と Kaggle アップロード対象

| ファイル | 用途 | 保存先 | Kaggle アップロード |
|----------|------|--------|---------------------|
| `train_with_su10.csv` | ローカル学習用（事前結合済み） | `data/processed/` | ❌ **不要** |
| `test_with_su10.csv` | ローカルテスト用（10行、構造確認） | `data/processed/` | ❌ **不要** |
| `su10_external_regime.csv` | Kaggle NB 推論時の join 用マッピング | `data/processed/` | ✅ **必須** |
| `inference_bundle.pkl` | 学習済みモデル | `artifacts/SU10/` | ✅ **必須** |
| `model_meta.json` | メタデータ | `artifacts/SU10/` | ✅ **必須** |
| `feature_list.json` | 特徴量リスト | `artifacts/SU10/` | ✅ **必須** |

**重要**: `test_with_su10.csv` は Kaggle にアップロード**しない**。
APIモードでは非公開テストセット（180行）が `predict()` 関数に渡されるため、
推論時に `su10_external_regime.csv` を使って join する必要がある。

### 4.4 生成パイプライン

```
1. SPY Historical Data を読み込み
   └─ data/histolical/spy-historical.csv

2. 特徴量を計算
   ├─ ボラティリティ指標（EWMA std）
   ├─ ボラレジーム（train 期間の分位点で分類）
   ├─ トレンド指標（MA 差分）
   ├─ トレンドレジーム（train 期間の分位点で分類）
   └─ ボラ調整リターン

3. su10_external_regime.csv を出力
   └─ date_id を主キーとするマッピングテーブル

4. train/test と結合
   ├─ train.csv + su10 → train_with_su10.csv
   └─ test.csv + su10 → test_with_su10.csv

5. Kaggle Dataset としてアップロード
   └─ su10_external_regime.csv + 学習済みモデル
```

### 4.5 スクリプト構成

```
scripts/su10/
├── build_su10_external_regime.py   # su10_external_regime.csv 生成
├── merge_train_test.py             # train/test との結合
└── upload_kaggle_dataset.py        # Kaggle Dataset アップロード（任意）
```

---

## 5. ローカル学習パイプラインでの利用

### 5.1 事前結合済み CSV の利用

```python
import pandas as pd

# 事前結合済みデータを直接読み込み
train = pd.read_csv("data/processed/train_with_su10.csv")

# 以降は既存の SU1〜SU9 生成・前処理・モデル学習フローをそのまま適用
```

### 5.2 結合処理（初回のみ）

```python
import pandas as pd

# データ読み込み
train = pd.read_csv("data/raw/train.csv")
test = pd.read_csv("data/raw/test.csv")
su10 = pd.read_csv("data/processed/su10_external_regime.csv")

# left join（date_id をキーに）
train_with_su10 = train.merge(su10, on="date_id", how="left")
test_with_su10 = test.merge(su10, on="date_id", how="left")

# 保存
train_with_su10.to_csv("data/processed/train_with_su10.csv", index=False)
test_with_su10.to_csv("data/processed/test_with_su10.csv", index=False)
```

### 5.2 欠損値の扱い

- date_id 0〜779 は SPY データなし → SU10 列は NaN
- LightGBM は NaN をネイティブに処理可能
- 必要に応じて 0 埋め or 中央値補完も検討

### 5.3 特徴選択・前処理

`configs/feature_generation.yaml` に SU10 ブロックを追加:

```yaml
su10:
  enabled: true
  external_data_path: data/histolical/spy-historical.csv
  output_path: data/processed/su10_external_regime.csv
  id_column: date_id
  
  # ボラティリティ設定
  volatility:
    ewm_halflife_short: 20
    ewm_halflife_long: 60
    quantile_low: 0.33
    quantile_high: 0.66
  
  # トレンド設定
  trend:
    ewm_halflife_short: 20
    ewm_halflife_long: 60
    quantile_down: 0.33
    quantile_up: 0.66
  
  # リターン設定
  returns:
    periods: [5, 20]
    vol_adj_period: 5
    winsorize_quantiles: [0.01, 0.99]
  
  # 列の分類
  numeric_cols:
    - su10_spx_ret_5d
    - su10_spx_ret_20d
    - su10_spx_ewmstd_20d
    - su10_spx_ewmstd_60d
    - su10_spx_vol_ratio
    - su10_spx_vol_level
    - su10_spx_trend_indicator
    - su10_spx_ret_vol_adj_5d
  
  categorical_cols:
    - su10_spx_vol_regime_low
    - su10_spx_vol_regime_mid
    - su10_spx_vol_regime_high
    - su10_spx_trend_regime_down
    - su10_spx_trend_regime_flat
    - su10_spx_trend_regime_up
  
  metadata:
    artifacts_dir: artifacts/SU10
    depends_on: []
    expected_usage: "External market regime features (S&P 500 volatility/trend)"
    numpy_version: 1.26.4
    status: pending
    decision: pending
```

---

## 6. Kaggle Notebook（推論）での利用

### 6.1 コンペの評価構造

- 本コンペは **APIモード**（`DefaultInferenceServer`）で評価される
- `predict(test: pl.DataFrame) -> float` 関数が呼ばれ、非公開テストセット（180行）が渡される
- 公開 test.csv（10行）はモック（構造サンプル）であり、評価には使われない

### 6.2 入力 Dataset 構成

Kaggle Notebook では以下を入力としてマウントする:

1. **公式コンペ Dataset**: `train.csv`, `test.csv` 等（APIモードでは直接使わない）
2. **学習済みモデル Dataset**:
   - `inference_bundle.pkl`
   - `feature_list.json`
   - `model_meta.json`
   - `su10_external_regime.csv`（join 用マッピングテーブル）

### 6.3 APIモードでの推論実装

```python
import polars as pl
import pandas as pd
import joblib
import json

# モデルとSU10マッピングをロード（Notebook初期化時）
bundle = joblib.load("/kaggle/input/su10-model/inference_bundle.pkl")
with open("/kaggle/input/su10-model/feature_list.json") as f:
    feature_list = json.load(f)
su10 = pd.read_csv("/kaggle/input/su10-model/su10_external_regime.csv")

def predict(test: pl.DataFrame) -> float:
    """
    APIモードで呼ばれる推論関数
    test: 非公開テストセット（180行）が渡される
    """
    # Polars → Pandas 変換
    test_pd = test.to_pandas()
    
    # SU10 を date_id で join
    test_pd = test_pd.merge(su10, on="date_id", how="left")
    
    # 特徴量を揃えて推論
    X_test = test_pd[feature_list]
    prediction = bundle["pipeline"].predict(X_test)
    
    # 1行ずつ呼ばれるため、スカラーで返す
    return float(prediction[0])
```

### 6.4 重要なポイント

1. **su10_external_regime.csv は学習済みモデルと一緒にアップロード**
   - date_id 0〜8989 の全範囲をカバー
   - 非公開テストセットの date_id も含まれている必要あり

2. **APIモードでは test.csv を直接読まない**
   - `predict()` 関数に渡される `test` DataFrame を使用
   - 非公開テストセット（180行）が逐次渡される

3. **join は推論時に実行**
   - 事前結合済み test_with_su10.csv は**ローカルテスト用**
   - Kaggle NB では su10_external_regime.csv を join 用マッピングとして使用

---

## 7. 制約・注意事項

### 7.1 規約順守

- 利用する外部データは **「公開・自由にアクセス可能」** であること
- 他参加者も再現可能な形で共有すること
- Kaggle Dataset として公開 or コンペルールに従った形で共有すること

### 7.2 リーク防止

- **t 時点の SU10 特徴は t までの情報のみから計算すること**
- 未来の価格・指標・リビジョン後データは一切使わない
- EWMA/rolling は「時刻 t までの過去のみ」を参照する
- レジーム分類の分位点は **train 期間のみ** で fit し、test には持ち越す

### 7.3 再現性

- SU10 生成スクリプト（`scripts/su10/build_su10_external_regime.py`）はリポジトリにコミット
- どの外部ソース・パラメータで SU10 が作られたかを明示する
- `model_meta.json` に SU10 の Dataset 名・バージョンを必ず記録する:
  ```json
  {
    "su10": {
      "enabled": true,
      "dataset_version": 1,
      "feature_list": ["su10_spx_ret_5d", "su10_spx_vol_level", ...]
    }
  }
  ```

### 7.4 列数・複雑性

- SU10 は **10〜30 列程度** に抑える
- 他 SU（特に SU7/SU8/SU9）との併用時でも全体の列数が過大にならないよう管理する
- まずは S&P 単独で効果を検証し、効果が確認されてから拡張を検討する

---

## 8. クラス構成（想定）

### 8.1 ファイル構成

```
src/feature_generation/su10/
├── __init__.py
├── feature_su10.py     # SU10Config, SU10FeatureGenerator
├── train_su10.py       # 学習パイプライン
└── predict_su10.py     # 推論パイプライン

scripts/su10/
├── build_su10_external_regime.py   # CSV 生成
└── upload_kaggle_dataset.py        # Kaggle アップロード

tests/feature_generation/
└── test_su10.py        # 単体テスト
```

### 8.2 クラス設計

```python
@dataclass
class SU10Config:
    """SU10 External Regime 設定"""
    external_data_path: str = "data/histolical/spy-historical.csv"
    output_path: str = "data/processed/su10_external_regime.csv"
    id_column: str = "date_id"
    
    # ボラティリティ設定
    ewm_halflife_short: int = 20
    ewm_halflife_long: int = 60
    vol_quantile_low: float = 0.33
    vol_quantile_high: float = 0.66
    
    # トレンド設定
    trend_ewm_halflife_short: int = 20
    trend_ewm_halflife_long: int = 60
    trend_quantile_down: float = 0.33
    trend_quantile_up: float = 0.66
    
    # リターン設定
    return_periods: list = field(default_factory=lambda: [5, 20])
    vol_adj_period: int = 5
    winsorize_low: float = 0.01
    winsorize_high: float = 0.99


class SU10FeatureGenerator:
    """外部レジーム特徴生成クラス"""
    
    def __init__(self, config: SU10Config):
        self.config = config
        self.vol_quantiles_: Optional[Tuple[float, float]] = None
        self.trend_quantiles_: Optional[Tuple[float, float]] = None
    
    def fit(self, external_df: pd.DataFrame, train_date_ids: np.ndarray) -> "SU10FeatureGenerator":
        """train 期間のデータから分位点を算出"""
        ...
    
    def transform(self, external_df: pd.DataFrame) -> pd.DataFrame:
        """外部レジーム特徴を生成"""
        ...
    
    def fit_transform(self, external_df: pd.DataFrame, train_date_ids: np.ndarray) -> pd.DataFrame:
        """fit + transform"""
        return self.fit(external_df, train_date_ids).transform(external_df)
```

---

## 9. PoC とロールバック方針

### 9.1 導入順

1. SU10 External Regime Dataset を生成（S&P のみ）
2. SU1+SU5+SU10 で OOF 評価
3. OOF 改善が確認されたら LB 提出（最大1回）

### 9.2 評価指標

- **主指標**: OOF RMSE（低いほど良い）
- **副指標**: OOF MSR / MSR_down（高いほど良い）
- **ベースライン**: SU1+SU5 (LB 0.681)

### 9.3 ロールバック条件

- OOF 改善が **fold 間分散を考慮して +0.3〜0.5σ 未満** の場合は SU10 をオフに戻す
- LB で明確に悪い場合（0.681 未満）は即座に非採用
- SU7/SU8/SU9 の教訓: **OOF 改善 ≠ LB 改善** のため、LB 結果を最終判断基準とする

### 9.4 SU7/SU8/SU9 との違い

| SU | 情報源 | リスク | SU10との違い |
|----|--------|--------|--------------|
| SU7 | 内部データからモメンタム | レジームミスマッチ | SU10は外部市場情報 |
| SU8 | 内部データからボラ | 情報の重複 | SU10は外部市場情報 |
| SU9 | カレンダー情報 | 過学習 | SU10は市場実績ベース |
| SU10 | 外部市場データ | 新規情報軸 | train/test と独立 |

**期待**: 外部市場データは train/test 内部データとは異なる情報軸のため、過学習リスクが低い可能性がある。

---

## 10. 今後の拡張

### 10.1 追加データソース候補

| ソース | 説明 | 優先度 |
|--------|------|--------|
| VIX | 恐怖指数 | 高 |
| 金利（FRED） | 長短金利差・スプレッド | 中 |
| セクター ETF | セクターローテーション | 低 |
| コモディティ | 金・原油など | 低 |

### 10.2 追加特徴量候補

- マクロスプレッド（例: 10Y-2Y 金利差）
- VIX ベースのレジームタグ
- クラスタリングによる市場レジーム ID

### 10.3 段階的アプローチ

1. **Phase 1**: S&P 500 / SPY のみで効果検証（本仕様書）
2. **Phase 2**: VIX 追加（効果確認後）
3. **Phase 3**: マクロ指標追加（必要に応じて）

---

## 11. 参照

- `docs/feature_generation/SU8.md`: ボラティリティ・レジーム特徴（内部データ版）
- `docs/feature_generation/SU7.md`: モメンタム・リバーサル特徴
- `docs/feature_generation/SU9.md`: カレンダー・季節性特徴
- `configs/feature_generation.yaml`: 特徴量生成設定
- `data/histolical/spy-historical.csv`: SPY 日次データ（date_id マッピング済み）
- `data/histolical/sp-historical.csv`: S&P 500 指数日次データ
