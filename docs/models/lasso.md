# Lasso ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ä»•æ§˜æ›¸

æœ€çµ‚æ›´æ–°: 2025-12-12

## å®Ÿè£…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹

**Status**: â¬œ **æœªç€æ‰‹**

### å®Ÿè£…äºˆå®š
- â¬œ `src/models/lasso/train_lasso.py`: å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- â¬œ `configs/models/lasso.yaml`: YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
- â¬œ Unit tests: `tests/models/test_lasso.py`

### æˆæœç‰©
- â¬œ `artifacts/models/lasso/inference_bundle.pkl`
- â¬œ `artifacts/models/lasso/oof_predictions.csv`
- â¬œ `artifacts/models/lasso/cv_fold_logs.csv`
- â¬œ `artifacts/models/lasso/model_meta.json`
- â¬œ `artifacts/models/lasso/coefficients.csv` ï¼ˆä¿‚æ•°å‡ºåŠ›ï¼‰
- â¬œ `artifacts/models/lasso/submission.csv`

---

## 1. ç›®çš„ã¨ä½ç½®ã¥ã‘

### 1.1 ãƒ¢ãƒ‡ãƒ«é¸å®šãƒ•ã‚§ãƒ¼ã‚ºã§ã®å½¹å‰²

- **ç›®çš„**: L1æ­£å‰‡åŒ–ã«ã‚ˆã‚‹ç‰¹å¾´é¸æŠåŠ¹æœã‚’æŒã¤ç·šå½¢ãƒ¢ãƒ‡ãƒ«
- **æœŸå¾…åŠ¹æœ**: 
  - åŠ¹ã„ã¦ã„ãªã„ç‰¹å¾´ã®ä¿‚æ•°ã‚’0ã«æ½°ã™ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ï¼‰
  - ã€Œç·šå½¢ã§è¦‹ã‚‹ã¨ã€ã©ã®ç‰¹å¾´ã‚’ã©ã“ã¾ã§ä½¿ã£ã¦ã„ã‚‹ã‹ã€ã®è¨ºæ–­
  - é«˜ã„ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å¤šæ§˜æ€§ï¼ˆç·šå½¢ vs éç·šå½¢ï¼‰
- **æ¯”è¼ƒå¯¾è±¡**: 
  - LGBM ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆOOF RMSE: 0.012164, LB: 0.681ï¼‰
  - Ridgeï¼ˆL2æ­£å‰‡åŒ–ã¨ã®æ¯”è¼ƒï¼‰

### 1.2 Lassoã®ç‰¹å¾´

- **L1æ­£å‰‡åŒ–**: ä¿‚æ•°ã®çµ¶å¯¾å€¤å’Œã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’èª²ã™
- **ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§**: ä¸è¦ãªç‰¹å¾´ã®ä¿‚æ•°ãŒå®Œå…¨ã«0ã«ãªã‚‹
- **ç‰¹å¾´é¸æŠåŠ¹æœ**: è‡ªå‹•çš„ã«é‡è¦ãªç‰¹å¾´ã®ã¿ã‚’ä½¿ç”¨
- **ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¾å­˜**: ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æ•æ„Ÿï¼ˆ**StandardScalerå¿…é ˆã€å¤–ã™ã¨ä¿‚æ•°è§£é‡ˆãŒç ´ç¶»**ï¼‰

### 1.3 å‰ææ¡ä»¶

- **ç‰¹å¾´ã‚»ãƒƒãƒˆ**: FS_compactï¼ˆ116åˆ—ï¼‰ã‚’å›ºå®šï¼ˆFeature Selection Phase ã§ã®çµè«–ã¨æ•´åˆï¼‰
- **CVè¨­å®š**: TimeSeriesSplit, n_splits=5, gap=0ï¼ˆLGBMã¨åŒä¸€ï¼‰
- **è©•ä¾¡æŒ‡æ¨™**:
  - **ä¸»æŒ‡æ¨™**: OOF RMSEï¼ˆé¸å®šãƒ•ã‚§ãƒ¼ã‚ºã®æœ€é‡è¦æŒ‡æ¨™ï¼‰
  - **è£œåŠ©æŒ‡æ¨™**: äºˆæ¸¬ç›¸é–¢ï¼ˆvs LGBMï¼‰ã€OOF MSRï¼ˆãƒˆãƒ¬ãƒ¼ãƒ‰è¦³ç‚¹ã§ã®ç›£è¦–ï¼‰
- **ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**: **å¿…é ˆ**

---

## 2. æŠ€è¡“ä»•æ§˜

### 2.1 å…¥å‡ºåŠ›

| é …ç›® | ä»•æ§˜ |
|------|------|
| å…¥åŠ› | `data/raw/train.csv`, `data/raw/test.csv` |
| ç‰¹å¾´é‡ç”Ÿæˆ | SU1 + SU5 â†’ tier3é™¤å¤– â†’ 116åˆ— |
| å‡ºåŠ› | `artifacts/models/lasso/` é…ä¸‹ã«æˆæœç‰© |
| è¿½åŠ å‡ºåŠ› | `coefficients.csv`: ç‰¹å¾´é‡ä¿‚æ•°ä¸€è¦§ |

### 2.2 ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹é€ 

```
ç”Ÿãƒ‡ãƒ¼ã‚¿ (94åˆ—)
    â†“
[SU1FeatureAugmenter + SU5FeatureAugmenter]  # æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†åˆ©ç”¨
    â†“
åˆè¨ˆ 577åˆ—
    â†“
[tier3 feature exclusion]  # configs/feature_selection/tier3/excluded.json
    â†“
116åˆ— (FS_compact)
    â†“
[GroupImputers: M/E/I/P/S]  # æ—¢å­˜å‰å‡¦ç†å†åˆ©ç”¨
    â†“
[SimpleImputer]  # æ®‹ä½™NaNå‡¦ç†
    â†“
[StandardScaler]  # â˜… Lassoå¿…é ˆï¼šç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    â†“
[Lasso]  # â˜… L1æ­£å‰‡åŒ–ç·šå½¢ãƒ¢ãƒ‡ãƒ«
```

### 2.3 åˆæœŸãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

```python
lasso_params = {
    "alpha": 0.001,          # æ­£å‰‡åŒ–å¼·åº¦ï¼ˆå°ã•ã‚ã‹ã‚‰é–‹å§‹ï¼‰
    "fit_intercept": True,   # åˆ‡ç‰‡ã‚’å­¦ç¿’
    "max_iter": 10000,       # åæŸã¾ã§ã®æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    "tol": 1e-4,             # åæŸåˆ¤å®šé–¾å€¤
    "selection": "cyclic",   # åº§æ¨™é™ä¸‹æ³•ã®é¸æŠæ–¹å¼
    "random_state": 42,
}
```

### 2.4 alpha ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

Lassoã®ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯`alpha`ã®ã¿ã€‚`LassoCV`ã§è‡ªå‹•é¸æŠ:

```python
from sklearn.linear_model import LassoCV

# LassoCVã‚’ä½¿ç”¨ã—ãŸè‡ªå‹•alphaé¸æŠ
# Lasso ã¯ alpha ãŒå¤§ãã™ãã‚‹ã¨å…¨ä¿‚æ•°ãŒ0ã«ãªã‚‹
alphas = np.logspace(-5, -1, 50)  # 0.00001 ã€œ 0.1
model = LassoCV(alphas=alphas, cv=5, max_iter=10000)
```

> **âš ï¸ æ™‚ç³»åˆ—CVã«é–¢ã™ã‚‹æ³¨æ„**
>
> `LassoCV(cv=5)` ã®å†…éƒ¨CVã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ãƒ©ãƒ³ãƒ€ãƒ ãªK-Foldåˆ†å‰²ã‚’è¡Œã„ã¾ã™ã€‚
> å¤–å´ã®CVï¼ˆTimeSeriesSplitï¼‰ãŒfoldé–“ã®ãƒªãƒ¼ã‚¯ã‚’é˜²ã„ã§ã„ã‚‹ãŸã‚è‡´å‘½çš„ãªå•é¡Œã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€
> å³å¯†ã«æ™‚ç³»åˆ—ã‚’å®ˆã‚ŠãŸã„å ´åˆã¯ä»¥ä¸‹ã®é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™:
> 1. `cv=TimeSeriesSplit(n_splits=5)` ã‚’æ¸¡ã™
> 2. `--auto-alpha` ã‚’ä½¿ã‚ãšã€å¤–å´CVã§ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã‚’è¡Œã†
>
> æœ¬ãƒ•ã‚§ãƒ¼ã‚ºã§ã¯ã€Œã¾ãšå›ºå®šalphaã§ä½ç½®ç¢ºèª â†’ å¿…è¦ã«å¿œã˜ã¦è‡ªå‹•é¸æŠã§å¾®èª¿æ•´ã€ã®æ–¹é‡ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

### 2.5 Ridgeã¨Lassoã®æ¯”è¼ƒ

| é …ç›® | Ridge (L2) | Lasso (L1) |
|------|------------|------------|
| æ­£å‰‡åŒ– | ä¿‚æ•°äºŒä¹—å’Œ | ä¿‚æ•°çµ¶å¯¾å€¤å’Œ |
| ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ | ãªã—ï¼ˆå…¨ä¿‚æ•°éã‚¼ãƒ­ï¼‰ | ã‚ã‚Šï¼ˆä¸€éƒ¨ä¿‚æ•°ãŒã‚¼ãƒ­ï¼‰ |
| ç‰¹å¾´é¸æŠåŠ¹æœ | ãªã— | ã‚ã‚Š |
| å¤šé‡å…±ç·šæ€§ | å¼·ã„ | å¼±ã„ |
| è§£æè§£ | ã‚ã‚Š | ãªã—ï¼ˆåå¾©æ³•ï¼‰ |
| alphaç¯„å›² | åºƒã„ | ç‹­ã„ï¼ˆæ„Ÿåº¦ãŒé«˜ã„ï¼‰ |

---

## 3. å®Ÿè£…è©³ç´°

### 3.1 ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
src/models/lasso/
â”œâ”€â”€ __init__.py           # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
â””â”€â”€ train_lasso.py        # ãƒ¡ã‚¤ãƒ³å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

configs/models/
â””â”€â”€ lasso.yaml            # YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

tests/models/
â””â”€â”€ test_lasso.py         # ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
```

### 3.2 train_lasso.py ã®å®Ÿè£…è¦ä»¶

#### 3.2.1 å¿…é ˆæ©Ÿèƒ½

1. **å¼•æ•°ãƒ‘ãƒ¼ã‚¹**: `argparse`ã§ä»¥ä¸‹ã‚’å—ã‘ä»˜ã‘ã‚‹
   - `--data-dir`: ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
   - `--out-dir`: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
   - `--feature-tier`: ä½¿ç”¨ã™ã‚‹tier
   - `--n-splits`, `--gap`: CVè¨­å®š
   - Lassoãƒã‚¤ãƒ‘ãƒ©: `--alpha`, `--auto-alpha`ï¼ˆLassoCVä½¿ç”¨ãƒ•ãƒ©ã‚°ï¼‰

2. **å‰å‡¦ç†**: StandardScalerã‚’è¿½åŠ 
   ```python
   from sklearn.preprocessing import StandardScaler
   from sklearn.impute import SimpleImputer
   from sklearn.linear_model import Lasso, LassoCV
   ```

3. **ä¿‚æ•°å‡ºåŠ›**: å„foldã®ä¿‚æ•°ã‚’CSVã§ä¿å­˜

### 3.3 ã‚³ãƒ¼ãƒ‰ã‚¹ã‚±ãƒ«ãƒˆãƒ³

```python
"""Lasso training script with unified CV framework."""

from __future__ import annotations

import argparse
import json
import pickle
from pathlib import Path
from typing import Any

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.linear_model import Lasso, LassoCV
from sklearn.model_selection import TimeSeriesSplit
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.feature_generation.su5.train_su5 import (
    SU5FeatureAugmenter,
    load_preprocess_policies,
    load_su1_config,
    load_su5_config,
)
from src.models.common.cv_utils import (
    CVConfig,
    aggregate_fold_results,
    compute_fold_metrics,
    create_cv_splits,
)
from src.models.common.feature_loader import get_excluded_features


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Train Lasso model")
    parser.add_argument("--data-dir", type=str, default="data/raw")
    parser.add_argument("--out-dir", type=str, default="artifacts/models/lasso")
    parser.add_argument(
        "--config-path", type=str, default="configs/feature_generation.yaml"
    )
    parser.add_argument("--preprocess-config", type=str, default="configs/preprocess.yaml")
    parser.add_argument("--feature-tier", type=str, default="tier3")
    parser.add_argument("--n-splits", type=int, default=5)
    parser.add_argument("--gap", type=int, default=0)
    # Lasso specific
    parser.add_argument("--alpha", type=float, default=0.001)
    parser.add_argument("--auto-alpha", action="store_true", help="Use LassoCV for auto alpha selection")
    return parser.parse_args()


def build_lasso_pipeline(alpha: float = 0.001) -> Pipeline:
    """Build Lasso pipeline with StandardScaler."""
    return Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
        ("model", Lasso(
            alpha=alpha,
            fit_intercept=True,
            max_iter=10000,
            tol=1e-4,
            random_state=42,
        )),
    ])


def build_lassocv_pipeline() -> Pipeline:
    """Build LassoCV pipeline for auto alpha selection."""
    alphas = np.logspace(-5, -1, 50)
    return Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
        ("model", LassoCV(
            alphas=alphas,
            cv=5,
            max_iter=10000,
            random_state=42,
            n_jobs=-1,
        )),
    ])


def train_fold(
    X_train: pd.DataFrame,
    y_train: pd.Series,
    X_val: pd.DataFrame,
    alpha: float | None = None,
    auto_alpha: bool = False,
) -> tuple[Pipeline, np.ndarray, float]:
    """Train a single fold, return pipeline, predictions, and selected alpha."""
    if auto_alpha:
        pipeline = build_lassocv_pipeline()
    else:
        pipeline = build_lasso_pipeline(alpha=alpha or 0.001)
    
    pipeline.fit(X_train, y_train)
    val_pred = pipeline.predict(X_val)
    
    # Get actual alpha used
    model = pipeline.named_steps["model"]
    used_alpha = model.alpha_ if hasattr(model, "alpha_") else model.alpha
    
    return pipeline, val_pred, used_alpha


def extract_coefficients(pipeline: Pipeline, feature_cols: list[str]) -> pd.DataFrame:
    """Extract coefficients from trained Lasso model."""
    model = pipeline.named_steps["model"]
    coef_df = pd.DataFrame({
        "feature": feature_cols,
        "coefficient": model.coef_,
        "abs_coefficient": np.abs(model.coef_),
    })
    coef_df = coef_df.sort_values("abs_coefficient", ascending=False)
    return coef_df


def main() -> None:
    args = parse_args()
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»ç‰¹å¾´é‡ç”Ÿæˆï¼ˆæ—¢å­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    train_df = pd.read_csv(Path(args.data_dir) / "train.csv")
    test_df = pd.read_csv(Path(args.data_dir) / "test.csv")

    # SU1 + SU5 ç‰¹å¾´é‡ç”Ÿæˆ
    su1_cfg = load_su1_config(args.config_path)
    su5_cfg = load_su5_config(args.config_path)
    preprocess_policies = load_preprocess_policies(args.preprocess_config)
    augmenter = SU5FeatureAugmenter(su1_cfg, su5_cfg, preprocess_policies)

    train_aug = augmenter.fit_transform(train_df.copy())
    test_aug = augmenter.transform(test_df.copy())

    # tieré™¤å¤–
    excluded = get_excluded_features(args.feature_tier)
    feature_cols = [c for c in train_aug.columns if c not in excluded and c not in ["Date", "TARGET"]]
    
    X = train_aug[feature_cols]
    y = train_aug["TARGET"]
    X_test = test_aug[feature_cols]

    # CVè¨­å®š
    cv_config = CVConfig(n_splits=args.n_splits, gap=args.gap)
    splits = create_cv_splits(X, cv_config)

    # CVå­¦ç¿’
    fold_results = []
    alphas_used = []
    oof_preds = np.zeros(len(X))
    models = []
    all_coefficients = []

    for fold_idx, (train_idx, val_idx) in enumerate(splits):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

        pipeline, val_pred, used_alpha = train_fold(
            X_train, y_train, X_val,
            alpha=args.alpha,
            auto_alpha=args.auto_alpha,
        )
        oof_preds[val_idx] = val_pred
        models.append(pipeline)
        alphas_used.append(used_alpha)

        # Extract coefficients
        coef_df = extract_coefficients(pipeline, feature_cols)
        coef_df["fold"] = fold_idx
        all_coefficients.append(coef_df)

        metrics = compute_fold_metrics(y_val.values, val_pred, fold_idx)
        fold_results.append(metrics)
        
        n_nonzero = np.sum(np.abs(pipeline.named_steps["model"].coef_) > 1e-10)
        print(f"Fold {fold_idx}: RMSE={metrics.rmse:.6f}, alpha={used_alpha:.6f}, non-zero={n_nonzero}/{len(feature_cols)}")

    # é›†è¨ˆ
    summary = aggregate_fold_results(fold_results)
    print(f"\nOOF RMSE: {summary['oof_rmse']:.6f}")
    print(f"OOF MSR: {summary['oof_msr']:.6f}")
    print(f"Mean alpha: {np.mean(alphas_used):.6f}")

    # æˆæœç‰©ä¿å­˜
    # 1. inference_bundle.pkl
    test_preds = np.mean([m.predict(X_test) for m in models], axis=0)
    bundle = {
        "models": models,
        "augmenter": augmenter,
        "feature_cols": feature_cols,
        "excluded_features": excluded,
    }
    with open(out_dir / "inference_bundle.pkl", "wb") as f:
        pickle.dump(bundle, f)

    # 2. oof_predictions.csv
    oof_df = pd.DataFrame({
        "Date": train_aug["Date"],
        "TARGET": y,
        "prediction": oof_preds,
    })
    oof_df.to_csv(out_dir / "oof_predictions.csv", index=False)

    # 3. cv_fold_logs.csv
    fold_logs = pd.DataFrame([
        {
            "fold": r.fold_idx,
            "rmse": r.rmse,
            "msr": r.msr,
            "n_samples": r.n_samples,
            "alpha": alphas_used[i],
        }
        for i, r in enumerate(fold_results)
    ])
    fold_logs.to_csv(out_dir / "cv_fold_logs.csv", index=False)

    # 4. coefficients.csv (å…¨foldã®ä¿‚æ•°)
    coef_all = pd.concat(all_coefficients, ignore_index=True)
    coef_all.to_csv(out_dir / "coefficients.csv", index=False)

    # 5. coefficients_summary.csv (foldå¹³å‡)
    # æ³¨æ„: ã“ã‚Œã¯StandardScalerå¾Œã®ä¿‚æ•°ã€‚å…ƒã‚¹ã‚±ãƒ¼ãƒ«ã§ã®å¯„ä¸ã‚’è¦‹ã‚‹å ´åˆã¯
    # scaler.scale_ ã§å‰²ã‚Šæˆ»ã™å¿…è¦ãŒã‚ã‚‹
    coef_summary = (
        coef_all.groupby("feature")["coefficient"]
        .agg(["mean", "std"])
        .reset_index()
    )
    coef_summary["abs_mean"] = np.abs(coef_summary["mean"])
    coef_summary = coef_summary.sort_values("abs_mean", ascending=False)
    coef_summary.to_csv(out_dir / "coefficients_summary.csv", index=False)

    # 6. model_meta.json
    meta = {
        "model_type": "Lasso",
        "feature_tier": args.feature_tier,
        "n_features": len(feature_cols),
        "cv_config": {"n_splits": args.n_splits, "gap": args.gap},
        "hyperparameters": {
            "alpha": float(np.mean(alphas_used)),
            "auto_alpha": args.auto_alpha,
        },
        "oof_rmse": summary["oof_rmse"],
        "oof_msr": summary["oof_msr"],
        "n_nonzero_features_mean": int(np.mean([
            np.sum(np.abs(m.named_steps["model"].coef_) > 1e-10) for m in models
        ])),
    }
    with open(out_dir / "model_meta.json", "w") as f:
        json.dump(meta, f, indent=2)

    # 7. submission.csv
    submission = pd.DataFrame({
        "Date": test_aug["Date"],
        "TARGET": test_preds,
    })
    submission.to_csv(out_dir / "submission.csv", index=False)

    print(f"\nArtifacts saved to {out_dir}")


if __name__ == "__main__":
    main()
```

---

## 4. ãƒ†ã‚¹ãƒˆè¦ä»¶

### 4.1 ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

```python
# tests/models/test_lasso.py

import numpy as np
import pandas as pd
import pytest
from sklearn.linear_model import Lasso, LassoCV
from sklearn.preprocessing import StandardScaler


class TestLassoPipeline:
    """Test Lasso pipeline components."""

    def test_lasso_basic_fit(self, sample_train_data: pd.DataFrame) -> None:
        """Lasso can fit and predict."""
        X = sample_train_data.drop(columns=["Date", "TARGET"])
        y = sample_train_data["TARGET"]

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        model = Lasso(alpha=0.001, random_state=42)
        model.fit(X_scaled, y)
        preds = model.predict(X_scaled)

        assert len(preds) == len(y)
        assert not np.isnan(preds).any()

    def test_lasso_sparsity(self, sample_train_data: pd.DataFrame) -> None:
        """Lasso produces sparse coefficients."""
        X = sample_train_data.drop(columns=["Date", "TARGET"])
        y = sample_train_data["TARGET"]

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # With moderate alpha, some coefficients should be zero
        model = Lasso(alpha=0.01, random_state=42)
        model.fit(X_scaled, y)

        n_zero = np.sum(np.abs(model.coef_) < 1e-10)
        # At least some features should be zeroed out
        assert n_zero >= 0  # May vary depending on data

    def test_lasso_vs_ridge(self, sample_train_data: pd.DataFrame) -> None:
        """Lasso and Ridge give different sparsity patterns."""
        from sklearn.linear_model import Ridge

        X = sample_train_data.drop(columns=["Date", "TARGET"])
        y = sample_train_data["TARGET"]

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        lasso = Lasso(alpha=0.01, random_state=42)
        ridge = Ridge(alpha=1.0, random_state=42)

        lasso.fit(X_scaled, y)
        ridge.fit(X_scaled, y)

        # Lasso should have more zeros than Ridge
        lasso_zeros = np.sum(np.abs(lasso.coef_) < 1e-10)
        ridge_zeros = np.sum(np.abs(ridge.coef_) < 1e-10)
        
        assert lasso_zeros >= ridge_zeros

    def test_lassocv_selects_alpha(self, sample_train_data: pd.DataFrame) -> None:
        """LassoCV automatically selects alpha."""
        X = sample_train_data.drop(columns=["Date", "TARGET"])
        y = sample_train_data["TARGET"]

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        alphas = np.logspace(-5, -1, 20)
        model = LassoCV(alphas=alphas, cv=3, random_state=42)
        model.fit(X_scaled, y)

        assert hasattr(model, "alpha_")
        assert model.alpha_ in alphas or np.isclose(model.alpha_, alphas).any()

    def test_scaling_required(self, sample_train_data: pd.DataFrame) -> None:
        """Lasso results differ significantly with/without scaling."""
        X = sample_train_data.drop(columns=["Date", "TARGET"])
        y = sample_train_data["TARGET"]

        # Without scaling
        model1 = Lasso(alpha=0.001, random_state=42)
        model1.fit(X, y)

        # With scaling
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        model2 = Lasso(alpha=0.001, random_state=42)
        model2.fit(X_scaled, y)

        # Coefficients should be different
        assert not np.allclose(model1.coef_, model2.coef_)
```

---

## 5. æˆåŠŸåŸºæº–

### 5.1 å®šé‡åŸºæº–

| å„ªå…ˆåº¦ | æŒ‡æ¨™ | é–¾å€¤ | ç†ç”± |
|--------|------|------|------|
| **ä¸»æŒ‡æ¨™** | OOF RMSE | â‰¤ 0.015 | ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦è¨±å®¹ç¯„å›² |
| è£œåŠ© | äºˆæ¸¬ç›¸é–¢ï¼ˆvs LGBMï¼‰ | < 0.85 | é«˜ã„ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å¤šæ§˜æ€§ |
| è£œåŠ© | OOF MSR | > 0ï¼ˆç›£è¦–ã®ã¿ï¼‰ | ãƒˆãƒ¬ãƒ¼ãƒ‰è¦³ç‚¹ã§ã®å¥å…¨æ€§ç¢ºèª |
| å‚è€ƒ | éã‚¼ãƒ­ä¿‚æ•°æ•° | è¨˜éŒ² | ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã®ç¢ºèª |

> **ğŸ“Œ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å€™è£œã¨ã—ã¦ã®åˆ¤æ–­åŸºæº–**
>
> æ„æ€æ±ºå®šã¯RMSEã§è¡Œã„ã€MSRã¨ç›¸é–¢ã¯è£œåŠ©çš„ãªè¨ºæ–­æŒ‡æ¨™ã¨ã—ã¾ã™ã€‚
> RMSEã§LGBMã«å‹ã¤ã“ã¨ã¯æ±‚ã‚ãšã€**ç›¸é–¢ãŒååˆ†ä½ã‘ã‚Œã°ï¼ˆ< 0.85ï¼‰ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¦å“¡ã¨ã—ã¦ä¾¡å€¤ã‚ã‚Š**ã¨åˆ¤æ–­ã—ã¾ã™ã€‚

### 5.2 å®šæ€§åŸºæº–

- [ ] å­¦ç¿’ãŒæ­£å¸¸ã«å®Œäº†ï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ï¼‰
- [ ] æˆæœç‰©ãŒå…¨ã¦ç”Ÿæˆã•ã‚Œã‚‹
- [ ] ä¿‚æ•°CSVãŒæ­£ã—ãå‡ºåŠ›ã•ã‚Œã‚‹
- [ ] å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆruff, pyrightï¼‰ã‚’ãƒ‘ã‚¹
- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆãŒå…¨ã¦ãƒ‘ã‚¹

---

## 6. å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰

### 6.1 å­¦ç¿’å®Ÿè¡Œ

```bash
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆå›ºå®šalphaï¼‰
python -m src.models.lasso.train_lasso

# è‡ªå‹•alphaé¸æŠï¼ˆLassoCVï¼‰
python -m src.models.lasso.train_lasso --auto-alpha

# alphaæŒ‡å®š
python -m src.models.lasso.train_lasso --alpha 0.0001
```

### 6.2 ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
pytest tests/models/test_lasso.py -v
```

### 6.3 å“è³ªãƒã‚§ãƒƒã‚¯

```bash
ruff check src/models/lasso/
ruff format src/models/lasso/
pyright src/models/lasso/
```

---

## 7. è¨ºæ–­çš„æ´»ç”¨

### 7.1 ä¿‚æ•°åˆ†æ

Lassoã®ä¿‚æ•°ã‚’åˆ†æã™ã‚‹ã“ã¨ã§ã€ä»¥ä¸‹ã®æ´å¯ŸãŒå¾—ã‚‰ã‚Œã‚‹:

1. **é‡è¦ç‰¹å¾´é‡ã®ç‰¹å®š**: éã‚¼ãƒ­ä¿‚æ•°ã‚’æŒã¤ç‰¹å¾´é‡
2. **ç‰¹å¾´é‡ã‚°ãƒ«ãƒ¼ãƒ—ã®æ¯”è¼ƒ**: SU1 vs SU5 vs raw ã®ã©ã‚ŒãŒåŠ¹ã„ã¦ã„ã‚‹ã‹
3. **ç¬¦å·ã®è§£é‡ˆ**: æ­£è² ã®ä¿‚æ•°ã‹ã‚‰ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é–¢ä¿‚ã‚’ç†è§£

### 7.2 åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹

```python
# ä¿‚æ•°åˆ†æ
import pandas as pd

coef_df = pd.read_csv("artifacts/models/lasso/coefficients_summary.csv")

# éã‚¼ãƒ­ä¿‚æ•°ã®ã¿
nonzero = coef_df[coef_df["abs_mean"] > 1e-10]
print(f"Non-zero features: {len(nonzero)} / {len(coef_df)}")

# Top 20 é‡è¦ç‰¹å¾´é‡
print(nonzero.head(20))
```

---

## 8. å‚è€ƒãƒªãƒ³ã‚¯

- [scikit-learn Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)
- [scikit-learn LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html)
- [Ridgeä»•æ§˜æ›¸](ridge.md)
- [ElasticNetä»•æ§˜æ›¸](elasticnet.md)

---

## 9. æ³¨æ„äº‹é …ï¼ˆXGBoostå®Ÿè£…ã‹ã‚‰å¾—ãŸå…±é€šæ•™è¨“ï¼‰

### 9.1 ãƒ†ã‚¹ãƒˆäºˆæ¸¬æ™‚ã®featureãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã¯å­¦ç¿’æ™‚ã«å­˜åœ¨ã—ãªã„ã‚«ãƒ©ãƒ ï¼ˆ`is_scored`, `lagged_*`ç­‰ï¼‰ãŒå«ã¾ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã€‚
**å­¦ç¿’æ™‚ã®feature_colsã®ã¿ã‚’æŠ½å‡º**ã—ã¦ã‹ã‚‰äºˆæ¸¬ã‚’å®Ÿè¡Œï¼š
```python
test_features = test_df[feature_cols].copy()
test_pred = final_pipeline.predict(test_features)
```

### 9.2 submission.csv ã®ã‚·ã‚°ãƒŠãƒ«å¤‰æ›

ç”Ÿã®äºˆæ¸¬å€¤ï¼ˆexcess returnsï¼‰ã§ã¯ãªãã€**ç«¶æŠ€ã‚·ã‚°ãƒŠãƒ«å½¢å¼**ã«å¤‰æ›ã—ã¦å‡ºåŠ›ï¼š
```python
# ã‚·ã‚°ãƒŠãƒ«å¤‰æ›: pred * mult + 1.0, clipped to [0.9, 1.1]
signal_mult = 1.0
signal_pred = np.clip(test_pred * signal_mult + 1.0, 0.9, 1.1)

# ã‚«ãƒ©ãƒ åã¯ "prediction"ï¼ˆtargetå¤‰æ•°åã§ã¯ãªã„ï¼‰
submission_df = pd.DataFrame({
    "date_id": id_values,
    "prediction": signal_pred,
})
```

### 9.3 is_scored ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

submission.csvã«ã¯`is_scored==True`ã®è¡Œã®ã¿ã‚’å«ã‚ã‚‹ï¼ˆç«¶æŠ€è¦ä»¶ï¼‰ã€‚
