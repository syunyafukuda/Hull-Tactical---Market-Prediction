from __future__ import annotations

from typing import Any, Dict, Iterable, Mapping, cast

import numpy as np
import pandas as pd

from preprocess.M_group.m_group import MGroupImputer as _BaseMGroupImputer


class PGroupImputer(_BaseMGroupImputer):
	"""Imputer tailored for valuation (P-group) features.

	The implementation mirrors :class:`MGroupImputer` but adds P-specific behavior:

	- Default column discovery targets columns beginning with ``"P"``.
	- Helper columns generated by policies such as ``mask_plus_mean`` are renamed to
	  remain P-namespaced (``Pmask__`` / ``Pextra__``).
	- After fitting, values are clipped by a robust medianÂ±MAD envelope (configurable)
	  to damp extreme valuation swings. A quantile fallback is used when MAD is zero
	  or insufficient samples are available.
	"""

	CALENDAR_REQUIRED_POLICIES = {
		"dow_median",
		"dom_median",
		"month_median",
		"holiday_bridge",
		"time_interp",
	}

	def __init__(
		self,
		columns: Iterable[str] | None = None,
		policy: str = "ffill_bfill",
		rolling_window: int = 5,
		ema_alpha: float = 0.3,
		calendar_column: str | None = None,
		policy_params: Mapping[str, Any] | None = None,
		random_state: int = 42,
		*,
		mad_clip_scale: float = 4.0,
		mad_clip_min_samples: int = 25,
		enable_mad_clip: bool = True,
		fallback_quantile_low: float = 0.005,
		fallback_quantile_high: float = 0.995,
	) -> None:
		self._user_calendar_column = calendar_column
		self.mad_clip_scale = float(mad_clip_scale)
		self.mad_clip_min_samples = int(mad_clip_min_samples)
		self.enable_mad_clip = bool(enable_mad_clip)
		self.fallback_quantile_low = float(fallback_quantile_low)
		self.fallback_quantile_high = float(fallback_quantile_high)
		self._clip_bounds_: Dict[str, tuple[float, float]] = {}
		self._prefit_warnings: list[str] = []

		super().__init__(
			columns=columns,
			policy=policy,
			rolling_window=rolling_window,
			ema_alpha=ema_alpha,
			calendar_column=calendar_column,
			policy_params=policy_params,
			random_state=random_state,
		)

	# ------------------------------------------------------------------
	def fit(self, X: pd.DataFrame, y: Any = None):  # type: ignore[override]
		frame = self._ensure_dataframe(X).copy()

		selected_columns = self._resolve_columns(frame)
		numeric_columns: list[str] = []
		for col in selected_columns:
			if col not in frame.columns:
				continue
			frame.loc[:, col] = pd.to_numeric(frame[col], errors="coerce")
			numeric_columns.append(col)
		self.columns = numeric_columns

		calendar_column = self._resolve_calendar_column(frame)
		if calendar_column is not None and calendar_column in frame.columns:
			calendar_series = pd.to_datetime(frame[calendar_column], errors="coerce")
			if calendar_series.isna().any():
				self._prefit_warnings.append("calendar_column_contains_non_parseable_values")
			if calendar_series.duplicated().any():
				self._prefit_warnings.append("calendar_column_contains_duplicates")

		fitted = super().fit(frame, y)

		self._relabel_generated_columns()
		self._clip_bounds_ = self._compute_clip_bounds()

		if hasattr(self, "_state_") and isinstance(self._state_, dict):
			if self._prefit_warnings:
				warnings = self._state_.setdefault("warnings", [])
				if isinstance(warnings, list):
					warnings.extend(self._prefit_warnings)
			self._state_["mad_clip_bounds"] = dict(self._clip_bounds_)
			self._state_["mad_clip_scale"] = self.mad_clip_scale
			self._state_["mad_clip_min_samples"] = self.mad_clip_min_samples
			self._state_["enable_mad_clip"] = self.enable_mad_clip
			self._state_["fallback_quantile_low"] = self.fallback_quantile_low
			self._state_["fallback_quantile_high"] = self.fallback_quantile_high

		return fitted

	# ------------------------------------------------------------------
	def transform(self, X: pd.DataFrame):  # type: ignore[override]
		frame = self._ensure_dataframe(X).copy()
		for col in getattr(self, "columns_", []):
			if col in frame.columns:
				frame.loc[:, col] = pd.to_numeric(frame[col], errors="coerce")

		transformed = super().transform(frame)

		if self.enable_mad_clip and self._clip_bounds_:
			for col, (low, high) in self._clip_bounds_.items():
				if col in transformed.columns:
					transformed.loc[:, col] = transformed[col].clip(lower=low, upper=high)

		return transformed

	# ------------------------------------------------------------------
	def _resolve_columns(self, frame: pd.DataFrame) -> list[str]:
		if self.columns is None:
			return [c for c in frame.columns if isinstance(c, str) and c.startswith("P")]
		return [c for c in self.columns if isinstance(c, str)]

	def _resolve_calendar_column(self, frame: pd.DataFrame) -> str | None:
		calendar_column = self._user_calendar_column or self.calendar_column
		if self.policy in self.CALENDAR_REQUIRED_POLICIES and calendar_column is None:
			raise ValueError(
				f"Policy '{self.policy}' requires a calendar column but none was provided."
			)
		if calendar_column is not None and calendar_column not in frame.columns:
			raise KeyError(
				f"Calendar column '{calendar_column}' not found in input DataFrame."
			)
		return calendar_column

	def _relabel_generated_columns(self) -> None:
		rename_map: Dict[str, str] = {}
		extra_columns = getattr(self, "extra_columns_", [])
		if not extra_columns:
			return
		for col in extra_columns:
			rename_map[col] = self._rename_generated_column(col)

		if not rename_map:
			return

		train_filled = getattr(self, "_train_filled_", None)
		if isinstance(train_filled, pd.DataFrame):
			self._train_filled_ = train_filled.rename(columns=rename_map)

		self.extra_columns_ = [str(rename_map.get(col, col)) for col in extra_columns]
		if hasattr(self, "_output_columns_"):
			self._output_columns_ = [str(rename_map.get(col, col)) for col in getattr(self, "_output_columns_", [])]

		state = getattr(self, "_state_", None)
		if isinstance(state, dict):
			for key, value in list(state.items()):
				if isinstance(value, pd.DataFrame):
					state[key] = value.rename(columns=rename_map)
			mask_map = state.get("mask_map")
			if isinstance(mask_map, dict):
				state["mask_map"] = {k: rename_map.get(v, v) for k, v in mask_map.items()}

	def _rename_generated_column(self, name: str) -> str:
		if name.endswith("_missing_flag"):
			base_name = name[: -len("_missing_flag")]
			return f"Pmask__{base_name}"
		if name.startswith("P"):
			return name
		return f"Pextra__{name}"

	def _compute_clip_bounds(self) -> Dict[str, tuple[float, float]]:
		if not self.enable_mad_clip:
			return {}

		filled = getattr(self, "_train_filled_", None)
		if not isinstance(filled, pd.DataFrame):
			return {}

		bounds: Dict[str, tuple[float, float]] = {}
		q_low = float(self.fallback_quantile_low)
		q_high = float(self.fallback_quantile_high)
		use_quantile = 0.0 <= q_low < q_high <= 1.0

		for col in getattr(self, "columns_", []):
			if col not in filled.columns:
				continue
			numeric_series = cast(pd.Series, pd.to_numeric(filled[col], errors="coerce"))
			numeric_series = numeric_series.dropna()
			if numeric_series.empty:
				continue

			low = high = None
			values = numeric_series.to_numpy(dtype=float, copy=False)
			if values.size >= max(1, self.mad_clip_min_samples):
				median = float(np.median(values))
				mad = float(np.median(np.abs(values - median)))
				if np.isfinite(mad) and mad > 0.0 and np.isfinite(median):
					spread = float(self.mad_clip_scale) * mad
					low = median - spread
					high = median + spread

			if (low is None or high is None or not np.isfinite(low) or not np.isfinite(high) or high <= low) and use_quantile:
				low_q = float(numeric_series.quantile(q_low))
				high_q = float(numeric_series.quantile(q_high))
				if np.isfinite(low_q) and np.isfinite(high_q) and high_q > low_q:
					low, high = low_q, high_q

			if low is None or high is None or not np.isfinite(low) or not np.isfinite(high) or high <= low:
				continue

			bounds[col] = (float(low), float(high))

		return bounds

